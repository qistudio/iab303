{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>IAB303</b> - Data Analytics for Business Insight</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOWS - Threats and opportunities\n",
    "\n",
    "This session focuses on obtaining data from web pages, via a process called web scraping.\n",
    "\n",
    "The tasks to be completed are:\n",
    "1. Understanding how information is structured within a web page\n",
    "2. Finding specific information\n",
    "3. Retrieving information from web pages\n",
    "4. A business intelligence scenario to find threats/opportunities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping\n",
    "\n",
    "### 1. Understanding how information is structured within a web page\n",
    "\n",
    "One of the most common ways of serving information online is through web pages. Web page information is semi-structured using HTML (HyperText Markup Language).\n",
    "\n",
    "HTML represents documents as elements, with sub-elements branching out from containing elements. As they 'branch' out further and further, they form what is referred to as the DOM (Document Object Model) - a kind of 'tree' shaped format.\n",
    "\n",
    "A DOM tree has a 'head' element, and a 'body' element, with most of the relevant viewing content being stored in the 'body' e.g."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <div class=\"sub-element\"></div>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, open a web browser. Depending on the browser you are using, follow instructions in the following link to open its developer tools:\n",
    "\n",
    "https://www.lifewire.com/web-browser-developer-tools-3988965"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, a tabbed sub-window will appear that displays information about the current web page you have opened. It can tell you a lot about the page, although all we are concerned with is the 'Elements' section, which shows the actual HTML DOM tree of the page itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding specific information\n",
    "\n",
    "Now that we can load up a web page's HTML just from opening it in a browser, let's try something a bit more specific. \n",
    "\n",
    "The following web page is the 'Wikipedia' article for Australia:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Australia\n",
    "\n",
    "Open a new tab and go to this page. On the page, you'll see in the right sidebar that the capital of Australia is 'Canberra'.\n",
    "\n",
    "Simply right-click the text, and hit the 'Inspect'/'Inspect Element' option. This will load up the 'Developer Tools', which will not only open up the 'Elements' tab of the page, but will jump to the location of the element in which the information is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning check-in 1\n",
    "Throughout this notebook, we'll ask you to record an indicator of your learning. The following code facilitates this. Run the cell and follow the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to record and plot learning checkins\n",
    "import sys; sys.path.append('./.local_libs'); from learning_checkin import *\n",
    "# Run this cell to check-in\n",
    "learning_checkin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieving information from web pages\n",
    "\n",
    "So far, we have been given a clear understanding about how a page renders content in HTML, as well as how to trace information from a web page back to the element it is contained in within the DOM tree.\n",
    "\n",
    "In this task, we introduce 'BeautifulSoup', a powerful library for Python that enables us to automate information retrieval from a web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup can interpret the DOM tree from a HTML document, so that we can easily pull out elements from the page with simple expressions. Take for instance the following HTML that we load into a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_HTML_page = \\\n",
    "    '<html>'\\\n",
    "    '   <head>'\\\n",
    "    '   </head>'\\\n",
    "    '   <body>'\\\n",
    "    '      <div>Not Here</div>'\\\n",
    "    '      <div class=\"target\">The Text We Are After</div>'\\\n",
    "    '   </body>'\\\n",
    "    '</html>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BeautifulSoup, we first interpret the page into a variable. From here, there are many possible ways of getting the target element (element with the 'class' of value 'target'). \n",
    "\n",
    "The most obvious way for this scenario involves finding the first element with the class of 'target':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(some_HTML_page, \"html.parser\")\n",
    "\n",
    "for element in soup(attrs={'class' : 'target'}):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more complex situations, we might not know the target element's class value, but may know details about its previous element (e.g. the text inside the previous element):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = soup.find(string=\"Not Here\") # the text before\n",
    "print(element.find_next(\"div\"))  # the tag that you want to find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to run BeatifulSoup on an actual web page, we could simply call the 'requests' library to load down the raw text of that page. Here we specify a basic method for pulling down HTML from a real web page, by specifying its URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_HTML(url):\n",
    "    # get data from server\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling the Wikipedia page for Australia, we can then get its raw HTML using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Australia_Wiki_HTML = get_HTML('https://en.wikipedia.org/wiki/Australia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the first 500 characters of the page\n",
    "Australia_Wiki_HTML[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning check-in 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check in for your learning session\n",
    "learning_checkin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question is: What are details about the element in which the name of Australia's capital city is stored?\n",
    "\n",
    "ANSWER: From perusing the elements in the 'Developer Tools' window, we can state the following facts about our target element:\n",
    "\n",
    "* It has an 'a' tag\n",
    "* It is inside an element with a 'td' tag\n",
    "* The element with the 'td' tag is preceded by an element with a 'th' tag\n",
    "* The element with the 'th' tag contains the text 'Capital'\n",
    "\n",
    "So the code that would get the exact element we are after is described in the method below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_capital(HTML):\n",
    "    soup = BeautifulSoup(HTML, \"html.parser\") # the html input and the parser name\n",
    "    th_element = soup.find(string=\"Capital\") # the text that we are looking for\n",
    "    target_element = th_element.find_next(\"a\") # the tag that we are looking for\n",
    "    print(target_element)\n",
    "\n",
    "get_the_capital(Australia_Wiki_HTML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reading any further, follow this link (https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to learn more about the functions ('find', 'findNext') used in the code above.\n",
    "\n",
    "To demonstrate just how flexible our solution is, we can run the exact same method on a different country e.g. France:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "France_Wiki_HTML = get_HTML('https://en.wikipedia.org/wiki/France')\n",
    "get_the_capital(France_Wiki_HTML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning check-in 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check in for your learning session\n",
    "learning_checkin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. A Business Intelligence Scenario\n",
    "\n",
    "As a market analyst working for a tourism agency, your boss has approached you with a client in need of a recommendation regarding the top tourist destinations.\n",
    "\n",
    "While this may sound easy, in hopes that it will improve their tourism experience, the client has also requested that places that are more innovative be prioritised in the recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately for this task, the top tourist destinations can be found on the following web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tourism_destinations = 'https://en.wikipedia.org/wiki/World_Tourism_rankings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Developer Tools, identify things that could be used to isolate the names of the countries in the table, in the section entitled \"Most visited destinations by international tourist arrivals\". \n",
    "\n",
    "For this task, the details have been given, however, the code that retrieves the values is only half completed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details:\n",
    "- A 'span' element that is contained by a 'h2' element; the title of the target 'table' is inside the 'span' element.\n",
    "- A 'table' element proceeds the 'h2' element.\n",
    "- There are 'td' elements inside the 'table' element.\n",
    "- Each 'td' element has an attribute of 'align' with the value 'left'.\n",
    "- In each 'td' element, there is an 'a' element with the name of a given country inside it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tourist_locations = []\n",
    "\n",
    "Tourism_Wiki_HTML = get_HTML(???)\n",
    "soup = BeautifulSoup(???, \"html.parser\")\n",
    "\n",
    "span_element = soup.find(id=???)\n",
    "\n",
    "h2_element = span_element.parent #'h2' is the parent of the span element\n",
    "\n",
    "table_element = h2_element.find_next(???)\n",
    "\n",
    "for td_element in table_element.find_all(???,attrs={'align':'left'}): # a tag with specific attributes\n",
    "    a_element = td_element.find(???) # the tag we are looking for\n",
    "    if a_element != None:\n",
    "        top_tourist_locations.append(a_element.text)\n",
    "\n",
    "# If you enter the missing code, this will return a list of names of the top tourist locations.\n",
    "top_tourist_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that the client is also looking for places that have higher innovation, what could we use from a single country's Wikipedia page to determine this quality?\n",
    "\n",
    "Going back to 'https://en.wikipedia.org/wiki/Australia', the HDI of the country will give a good indication of this; so how do we describe the HDI?\n",
    "\n",
    "Once again, here are some details to help:\n",
    "\n",
    "   * The text 'HDI' is in an 'a' element.\n",
    "   * The 'a' element is in a 'th' element.\n",
    "   * The 'th' is proceeded by a 'td' element.\n",
    "   * The 'td' element contains an 'img' element.\n",
    "   * Next to the 'img' element is the HDI value.\n",
    "\n",
    "The code that retrieves the HDI from a country's Wikipedia page is included in the following method, but it is incomplete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_HDI(html):\n",
    "    soup = BeautifulSoup(html, ???)\n",
    "    a_element = soup.find('a',string=???)\n",
    "    th_element = a_element.parent\n",
    "    td_element = th_element.find_next(???)\n",
    "    #print(td_element.text)\n",
    "    return td_element.???.strip()\n",
    "\n",
    "# If you enter the missing code, this function will produce the value '0.903'\n",
    "get_country_HDI(France_Wiki_HTML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do to get the HDI of each country is to substitute each country's name into the Wikipedia country's URL, and to feed the returned HTML into the 'get_country_HDI' method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(top_tourist_locations)):\n",
    "    print(\"Country: \"+top_tourist_locations[i])\n",
    "    print(\"Ranking: \"+str(i+1))\n",
    "    print(\"HDI: \"+get_country_HDI(\n",
    "        get_HTML('https://en.wikipedia.org/wiki/'+top_tourist_locations[i].replace(' ','%20'))\n",
    "    ))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing rankings and HDIs, what would you state in your recommendation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning check-in 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check in for your learning session\n",
    "learning_checkin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise your learning check-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot your check-ins for this session\n",
    "plot_checkin()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "qut": {
   "creation_period": "2023_sem2",
   "nb_name": "B1-TOWS_threats_opportunities",
   "unit_code": "IAB303"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
