{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>IAB303</b> - Data Analytics for Business Insight</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 -  Opportunities and Threats\n",
    "\n",
    "In this module we focus on analysis of data that is **external** to the business, and look at why it is important for identifying opportunities for growth and threats to survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Kodak Case\n",
    "\n",
    "<img src=\"https://kevinuhrmacher.files.wordpress.com/2011/11/uhrmacher_kodak.jpg?w=1240\"></img>\n",
    "\n",
    "[Kevin Uhrmacher, 2011](https://kevinuhrmacher.wordpress.com/2011/11/10/the-end-of-kodaks-moment/)\n",
    "\n",
    "\n",
    "### Kodak Threats and Opportunities\n",
    "\n",
    "Read this Harvard Business Review article on [Kodak’s Downfall Wasn’t About Technology](https://hbr.org/2016/07/kodaks-downfall-wasnt-about-technology), and make a list of possible threats and opportunities.\n",
    "\n",
    "What does the author say is the main reason for Kodak's downfall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning about customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psycographic segmentation\n",
    "\n",
    "Watch this segement of[4 Main Types of Market Segmentation & Their Benefits](https://youtu.be/EQ2pgHbvK0A?t=206), and identify the kinds of data that might be analysed, and the benefits for the business of using this type of market segmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "with open('data/twitter_credentials.json', 'r') as file:\n",
    "    credentials = json.load(file)\n",
    "\n",
    "auth = tweepy.OAuthHandler(credentials['API_KEY'], credentials['API_SECRET'])\n",
    "auth.set_access_token(credentials['ACCESS_TOKEN'], credentials['ACCESS_SECRET'])\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tweets = api.search(q=\"#gardening\", lang = \"en\", count=50,include_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    print(tweet.created_at)\n",
    "    print(tweet.id)\n",
    "    print(tweet.text,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What kind of data do we receive for each tweet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "first_tweet = tweets[2]\n",
    "first_tweet._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What other data can we extract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    if 'media' in tweet.entities:\n",
    "        for image in  tweet.entities['media']:\n",
    "            url = image['media_url']\n",
    "            display(HTML('<img src=\"'+url+'\" width=\"30%\"/>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also get user information..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "first_tweet.user._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And even more detail is available on each user by querying the API on the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "api.get_user('andrewresearch')._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**DISCUSSION**\n",
    "* What is it that is different about social media data like twitter?\n",
    "* What other kinds of data sources produce this type of data?\n",
    "* How is this significant for business?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagging or Realtime data - tapping the stream\n",
    "\n",
    "Watch this video on [How Walmart is using Big Data & IOT](https://youtu.be/42xErufN1e8), and identify how external and internal information is blurred through realtime use of Internet of Things (IoT) technologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Streaming - Google Maps\n",
    "\n",
    "* What you get\n",
    "* What google gets\n",
    "* The feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Streaming data and analytics\n",
    "\n",
    "* What is it and why is it important? (Mike Gualtieri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Streaming Analytics:** Technology that ingests, analyses, and acts on high throughput of data from live data sources to identify patterns, detect urgent situations, and automate immediate actions in real time.\n",
    "> [Mike Gualtieri](https://tdwi.org/articles/2016/08/29/define-your-business-case-for-streaming-analytics.aspx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* All data originates in real time\n",
    "* Insights are perishable\n",
    "* How can you ... **right now**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### LEARN MORE\n",
    "  \n",
    "> \"Information derived from such analysis gives companies visibility into many aspects of their business and customer activity such as –service usage (for metering/billing), server activity, website clicks, and geo-location of devices, people, and physical goods –and enables them to respond promptly to emerging situations.\"\n",
    ">\n",
    "> [What is Streaming Data?](https://aws.amazon.com/streaming-data/)\n",
    "\n",
    "\n",
    "> \"The success of a streaming analytics program is critically bound to establishing a proper business case.\"\n",
    ">\n",
    "> [Define Your Business Case for Streaming Analytics](https://tdwi.org/articles/2016/08/29/define-your-business-case-for-streaming-analytics.aspx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Accessing Streaming Data from Twitter\n",
    "\n",
    "We need to be able to apply a function to each element of the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "        if 'media' in status.entities:\n",
    "            for image in  status.entities['media']:\n",
    "                url = image['media_url']\n",
    "                display(HTML('<img src=\"'+url+'\" width=\"30%\"/>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n",
    "myStream.filter(track=['#trump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing web based information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4\n",
    "#!pip install html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate that you now have the module installed, execute the following 'cell'. Provided that you have installed it correctly, the cell will run without error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HTML(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html = response.read()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this page (https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to learn more about the functions ('find', 'findNext') used in the code above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding opportunities and threats via web pages\n",
    "\n",
    "Information about threats and opportunities can be found on web pages. This information can be scraped to enable analysis.\n",
    "\n",
    "### A Web Scraping Scenario\n",
    "\n",
    "As a market analyst working for a tourism agency, your boss has approached you with a client in need of a recommendation regarding the top tourist destinations of 2018.\n",
    "\n",
    "While this may sound easy, in hopes that it will improve their tourism experience, the client has also requested that places that have high quality of life be prioritised in the recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately for this task, the top tourist destinations of 2018 are stored on the following URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tourism_destinations = 'https://en.wikipedia.org/wiki/World_Tourism_rankings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Developer Tools, identify things that could be used to isolate the names of the countries in the table, in the section entitled \"Most visited destinations by international tourist arrivals\". \n",
    "\n",
    "For this task, the details have been given, however, the code that retrieves the values is only half completed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details:\n",
    "     * A 'span' element contains a 'h2' element with the title of the target 'table' inside it.\n",
    "     * A 'table' element proceeds the 'span' element.\n",
    "     * There are 'td' elements inside the 'table' element.\n",
    "     * Each 'td' element has an attribute of 'align' with the value 'left'.\n",
    "     * In each 'td' element, there is an 'a' element with the name of a given country inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tourist_locations = []\n",
    "\n",
    "Tourism_Wiki_HTML = get_HTML('https://en.wikipedia.org/wiki/World_Tourism_rankings')\n",
    "soup = BeautifulSoup(Tourism_Wiki_HTML, \"html.parser\")\n",
    "span_element = soup.find(text=\"Most visited destinations by international tourist arrivals\")\n",
    "h2_element = span_element.parent\n",
    "table_element = h2_element.findNext('table')\n",
    "for td_element in table_element.findAll('td',attrs={'align':'left'}):\n",
    "    a_element = td_element.find('a')\n",
    "    if a_element != None:\n",
    "        top_tourist_locations.append(a_element.text)\n",
    "\n",
    "# If you enter the missing code, this will return a list of names of the top tourist destinations for 2018.\n",
    "top_tourist_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that the client is also looking for places that have higher quality of life, what could we use from a single country's Wikipedia page to determine this quality?\n",
    "\n",
    "The HDI of the country will may be an indication of this; so how do we describe the HDI?\n",
    "\n",
    "Once again, here are some details to help:\n",
    "\n",
    "   * The text 'HDI' is in an 'a' element.\n",
    "   * The 'a' element is in a 'th' element.\n",
    "   * The 'th' is proceeded by a 'td' element.\n",
    "   * The 'td' element contains an 'img' element.\n",
    "   * Next to the 'img' element is the HDI value.\n",
    "\n",
    "The code that retrieves the HDI from a country's Wikipedia page is included in the following method, but it is incomplete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_HDI(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    a_element = soup.find('a',text=\"HDI\")\n",
    "    th_element = a_element.parent\n",
    "    td_element = th_element.findNext('td')\n",
    "    HDI_value = td_element.find('img').findNextSibling(text=True)\n",
    "    return HDI_value.strip()\n",
    "\n",
    "# If you enter the missing code, this function will produce the value '0.897'\n",
    "France_wiki = get_HTML(\"https://en.wikipedia.org/wiki/France\")\n",
    "get_country_HDI(France_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do to get the HDI of each country is to substitute each country's name into the Wikipedia country's URL, and to feed the returned HTML into the 'get_country_HDI' method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(top_tourist_locations)):\n",
    "    print(\"Country: \"+top_tourist_locations[i])\n",
    "    print(\"Ranking: \"+str(i+1))\n",
    "    print(\"HDI: \"+get_country_HDI(\n",
    "        get_HTML('https://en.wikipedia.org/wiki/'+top_tourist_locations[i].replace(' ','%20'))\n",
    "    ))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
