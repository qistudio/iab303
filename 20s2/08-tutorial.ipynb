{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAFZl-bzVGdC"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>IAB303</b> - Data Analytics for Business Insight</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2WCTqnqbvZIr"
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-G3dwjPvf7u"
   },
   "source": [
    "Sales forecasting is not uncommon for making rough revenue predictions in small and large businesses. Although sales forecasting is a great method of using past data and current goals to determine revenue potential, the process has a few major disadvantages. The longer a company has existed and has recorded past sales data, the more accurate they can forecast into the future and plan for unexpected events. New companies, however, are using guesswork when they use sales forecasting strategies, because they still do not have enough data.\n",
    "\n",
    "As you saw in the workshop, many companies rely uniquely on technical analysis and forecasting techniques as the one way to get estimations towards the future. Most CEO's and people wrongly believe that if a product reveals some past patterns or trends, then in the future, it will certainly behave like this. It is a mistake to believe that if a product displayed some revenues in the past, it will also present the same revenues in the future. \n",
    "\n",
    "This does not mean that we should drop forecasting techniques. On the contrary, we can take advantage of them to identify internal strengths and weaknesses in our business, but we must be aware that we cannot rely 100% in these tools to make predictions. If this was true, we could all predict the stock market by now and we would all be rich, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DB7GvZV_gkR"
   },
   "source": [
    "## Task 1: Understanding Forecasting Techniques in Sales\n",
    "\n",
    "In this lab session, we will analyse the behaviour of 10 stores that sell 50 different items. \n",
    "\n",
    "You are given 5 years of store-item sales data, and you are asked to predict 3 months of sales for 50 different items at 10 different stores.\n",
    "\n",
    "What's the best way to deal with seasonality? Should stores be modeled separately, or can you pool them together? These are all very interesting questions, but in this lab we will keep it simple by analysing only one store and one item: a specific item that is sold in the store that has the highest sales. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gy2jpW2mhzYD"
   },
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "\n",
    "# Data Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "# Forecasting libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf2GgLgNj6Mv"
   },
   "outputs": [],
   "source": [
    "# load the dataset containing the sales of different stores with different items\n",
    "df = pd.read_csv( 'data/sales.csv' )\n",
    "print( df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p4ybSAHLwd5N"
   },
   "source": [
    "How many stores do we have in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHFdD_-4wMvx"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# Store your result in variable num_stores\n",
    "\n",
    "num_stores = \n",
    "print( 'Total number of stores is: ' + str(num_stores) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_Xs95glETLq"
   },
   "source": [
    "What is the time period that this data has been collected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jNMIV9hEd91"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# Store your result in variables max_period and min_period\n",
    "\n",
    "max_period = \n",
    "min_period = \n",
    "\n",
    "print( 'This dataset has been collecte from ' + str(min_period) + ' to ' + str(max_period)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC4_WIxJGBRv"
   },
   "source": [
    "For plotting purposes, we are going to index this dataset over the date column. We do it in the follwoing way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Z92NgGYRdF5"
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.date,format='%Y-%m-%d')\n",
    "df.index = df['date']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjimbifqJHCA"
   },
   "source": [
    "Let's visualise the number of sales that each store obtained thoughout time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFQhiCMsJNRy"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(num_stores, figsize=(12, 16))\n",
    "\n",
    "# for each store...\n",
    "for store in df['store'].unique():\n",
    "\n",
    "  sales = df.loc[df['store'] == store, 'sales']\n",
    "  \n",
    "  # specifying figure options\n",
    "  ax = sales.plot(ax=axes[store-1])\n",
    "  ax.set_title('Store')\n",
    "  ax.set_ylabel('sales')\n",
    "  ax.grid()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7JUci7x9GTdm"
   },
   "source": [
    "Plotting the daily number of sales of each store seems a little bit confusing and hard to understand. Let's repeaat the visualisation, but this time with **weekly** number of sales that each store obtained throughout time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2v2-me0HQVq5"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(num_stores, figsize=(12, 16))\n",
    "\n",
    "# for each store...\n",
    "for store in df['store'].unique():\n",
    "  \n",
    "  # the resample function is a convenience method for frequency conversion of data\n",
    "  # basically we are converting our daily item sales into a weekly frequency\n",
    "  # this makes the data more clear for analysis\n",
    "  week_sales = df.loc[df['store'] == store, 'sales'].resample('W').sum()\n",
    "  \n",
    "  # specifying figure options\n",
    "  ax = week_sales.plot(ax=axes[store-1])\n",
    "  ax.set_title('Store')\n",
    "  ax.set_ylabel('sales')\n",
    "  ax.grid()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeAqYC8UTR0n"
   },
   "source": [
    "It seems that the performace of each store is similar. As you can see, every year the products show an initiation growth, they reach a maturity (the highest value) and then they start declining. This is usually the cycle of any product. the only difference is how long it takes to reach these increasing and decreasing phases and what is the highest number of sales the item reaches.\n",
    "We can see this better if we plot the sales of each store all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8nN9AHZV0Y6"
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "# for each store...\n",
    "for store in df['store'].unique():\n",
    "\n",
    "  # select the weekly number of sales \n",
    "  week_sales = df.loc[df['store'] == store, 'sales'].resample('W').sum()\n",
    "  # and plot the results with different colors for each store\n",
    "  week_sales.plot( color='C'+str(c), label='store'+str(store), figsize=(12, 8))\n",
    "  \n",
    "  # specifying figure options\n",
    "  plt.title('Store')\n",
    "  plt.ylabel('sales')\n",
    "  plt.legend()\n",
    "  \n",
    "  c = c + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBAgFuwDbB8C"
   },
   "source": [
    "Given this information, we can see that store number 2 has the highest sales, so let's make a dataframe that contains only the items and the number of sales in store number 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnG84PS4TkT3"
   },
   "outputs": [],
   "source": [
    "# get a dataframe that reprsents the average sales per store \n",
    "# YOUR CODE HERE\n",
    "avg_sales_per_store = \n",
    "\n",
    "renaming the grpuped column to 'avg sales'\n",
    "avg_sales_per_store = avg_sales_per_store.rename(columns={'sales':'avg sales'}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ8Uk3A7y29y"
   },
   "source": [
    "We can take a look at the entire data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByG9nYaky6QM"
   },
   "outputs": [],
   "source": [
    "# identify the store with the largest amount of sales (this should be store 2)\n",
    "# YOUR CODE HERE\n",
    "store_with_max_sales = \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# plot the results on a bar plot\n",
    "stores = avg_sales_per_store['store']\n",
    "barplot = plt.bar( stores, avg_sales_per_store['avg sales'] )\n",
    "\n",
    "# highllight store with hoghest number of sales\n",
    "barplot[ store_with_max_sales - 1 ].set_color('r')\n",
    "\n",
    "# figure options\n",
    "plt.title('Average sales per store')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BwsyC7U0wjQh"
   },
   "source": [
    "Let's focus on store number 2, since it has the highest number of sales. Let's pick up an individual item to analyse: item 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2VzMZ13xB4A"
   },
   "outputs": [],
   "source": [
    "# get the total sales of item 50 of the store with the highest volume of sales:\n",
    "# YOUR CODE HERE\n",
    "# put your result in a variable max_sales\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqMtTp5Ybzsv"
   },
   "source": [
    "Let's visualise the results of item 50  in store 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GPAuDntlSJm"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Number of sales of item ' + str(item) + ' in store ' + str(store_with_max_sales))\n",
    "plt.ylabel('Number of sales')\n",
    "\n",
    "\n",
    "weekly_sales = max_sales['sales'].resample('W').sum()\n",
    "weekly_sales = weekly_sales.to_frame()\n",
    "\n",
    "weekly_sales['sales'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QgNZSjRpZvtv"
   },
   "source": [
    "What is your understanding about the volume of sales in the above figure? We can notice two important things:\n",
    "1. There seems to be a **trend**: every year the number of sales is increasing. You can see this if you imagine a straight line connecting the peaks of the graph\n",
    "\n",
    "2. There are also lots of fluctuations in the volume of sales. There is a pattern that shows a decline in the amount of sales that reaches its minimum in the end of the year. It seems to be an item that has its peak of sales during summer, but starts to have a decline in sales towards winter. Can you guess what kind of item is it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dhQzNMZB8U6"
   },
   "source": [
    "## Task 2. The Forecasting Sales Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SStQHhMFAFnX"
   },
   "source": [
    "The above graph illustrates the volume of sales of a specific item in a given store. How do we predict the trends and the future sales in this  store?\n",
    "\n",
    "As you saw in the workshop, to determine this, we need to apply the general learning technique that was presented in the workshop:\n",
    "\n",
    "0. Analyse your data\n",
    "1. Separate our dataset into two samples:\n",
    "\n",
    "  1.1. A training set, which will be used to fit our data\n",
    "  \n",
    "  1.2. A test set, which will be used to test how good our model is predicting the data\n",
    "2. Select a predictive algorithm (a model to learn from our data)\n",
    "3. Fit our sample of data to this model\n",
    "4. Make prediction\n",
    "5. Evaluate how good the model is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAIRxR7APnaA"
   },
   "source": [
    "### Analyse your data\n",
    "\n",
    "So far, we identified the store that contains the maximum number of sales and we also selected within that store, the item with the highest volume of sales. As a CEO of a company, who constantly needs to be aware of market changes and conditions, what we did so far is not enough! It would be desirable to understand the trends in terms of sales of the products that the store is selling. This can be helpful for many reasons that were covered in the workshop, but as we saw, this analysis of trends does not solve or help us much: it indeed gives us a general overview of how the sales are going, but we cannot uniquely rely on this information. \n",
    "\n",
    "Also, as you learned in the workshop, different periods of the year stimulate the purchase of different items: in christmas we buy more foods, sweets and gifts; in summer we buy more outdoor activity products and so on. So it is also fundamental to take into consideration the market changes that occur due to season, weather, etc.\n",
    "\n",
    "What we have seen so far was the time series representation of our sales. As you could see, it looked like a very noisy signal from which we could not take much insight. A method to make it clear, and which we covered in the workshop, is the time series decomposition method.  Time series decomposition involves thinking of a series as a **combination of level, trend, seasonality, and noise components**.\n",
    "\n",
    "Decomposition provides a useful abstract model for thinking about time series generally and for better understanding problems during time series analysis and forecasting.\n",
    "\n",
    "In this lab session, you will discover time series decomposition and how to automatically split a time series into its components with Python.\n",
    "\n",
    "To help us identify product trends and seasonal changes, Python has a very good statistics library that can assist us on that, more precisely the function *seasonal_decompose*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iN2RIZvUTnX0"
   },
   "outputs": [],
   "source": [
    "# Apply the seasonal decomposition method to the sales dataset for a yearly frequency\n",
    "decomposed_sales = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFnWTdcNmyno"
   },
   "source": [
    "We can now observe the trends regarding the sales of our product. Note that the trend component is supposed to capture the slowly-moving overall level of the sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JIt7xDGm5ik"
   },
   "outputs": [],
   "source": [
    "# plot the general trend of the sales\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEEYdQ2JnIV8"
   },
   "source": [
    "What interpretations do you take from this graph?\n",
    "\n",
    "**YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zHCfaYNtnX58"
   },
   "source": [
    "We can also analyse the seasonal sales variation of our item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kuqvlB6fnfSw"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "# plotting the seasonal changes of the sales\n",
    "decomposed_sales.seasonal.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJNMiQjVyHJt"
   },
   "source": [
    "Now that we have a general understanding of our data, we can start the forecast method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDEr9laUBxmG"
   },
   "source": [
    "### Separate our Dataset\n",
    "\n",
    "We are going to forecast our data using our daily sales dataset. The first thing that it is important to know is the size of this datastet. Since this is a forecast approach, we will use the majority of our data to train our model and we will reserve the last 3 months to test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1eGo-R4SBxRY"
   },
   "outputs": [],
   "source": [
    "# 1. SEPARATE OUR DATASET:\n",
    "total_sales = len(max_sales)\n",
    "\n",
    "# we will split our data by selecting the last 3 months for prediction and the \n",
    "# remaining data for training\n",
    "data_split = 90 # 90 days corresponds to the three months\n",
    "\n",
    "# Allocate the data for training\n",
    "train = max_sales.iloc[0: total_sales - data_split - 1]\n",
    "\n",
    "# Put the remaining data of our dataset \n",
    "expected = max_sales.iloc[total_sales - data_split:]\n",
    "\n",
    "print('Total datapoints in the dataset: ' + str( total_sales )) \n",
    "print('Datapoints reserved for training: ' + str(len(train)))\n",
    "print('Datapoints reserved for testing: ' + str(len(expected)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T19:16:33.773337Z",
     "start_time": "2020-09-20T19:16:33.764085Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform the train and test sets in the format that was presented in the studio session\n",
    "# column 1: name 'ds' with the dates\n",
    "# column 2: name 'y' with the values we want to predict\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6jdH64UGEB5"
   },
   "source": [
    "### Define Learning Algorithm\n",
    "\n",
    "Next, we define the type of learning algorithm that we want to apply. Python's statistical Libraries offer us a wide range of learning algorithms that you can explore. For the purposes of this unit, we will explore Facebook's Prophet algorithm, which is based on a particular statistical learning method called Linear Regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T19:17:23.123916Z",
     "start_time": "2020-09-20T19:17:23.121144Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6FX6xzaeGv11"
   },
   "outputs": [],
   "source": [
    "# 2. DEFINE THE LEARNING ALGORITHM\n",
    "\n",
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6AtisrvKusN"
   },
   "source": [
    "### Fit the data to the model\n",
    "\n",
    "After defining our learning model and pluging in the right earning parameters, we need to fit our data to the model (learn from data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwf4jICmK7Ba"
   },
   "outputs": [],
   "source": [
    "# FIT THE MODEL TO THE DATA\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTEA_KNPL8e3"
   },
   "source": [
    "### Use our testset on the learned model to forecast our sales\n",
    "\n",
    "Let's use Prophet to try to estimate the last 3 months of our dataset. This way we can see how well the algorithm performed, since we have the true sales of the store for that time period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T19:19:04.122089Z",
     "start_time": "2020-09-20T19:19:04.120274Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tVzssZ12MOHF"
   },
   "outputs": [],
   "source": [
    "# 4. MAKE PREDICTIONS\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-tZk1mH1phX"
   },
   "source": [
    "In order to have a numerical validation of the model, instead of jus a graphical one, we can use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T19:19:27.714770Z",
     "start_time": "2020-09-20T19:19:27.712957Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6ogm_4vL1xDR"
   },
   "outputs": [],
   "source": [
    "# Compute the forecast error:\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the seasonal decomposition method to our sales dataset for a monthly frequency\n",
    "# to determine the trend\n",
    "decomposed_sales = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3IQ91fz93qT"
   },
   "source": [
    "## TASK 3: Make Predictions for Different Items and Different Years\n",
    "\n",
    "Try repeating the exercise, but now focusing on specific items over a certain timeframe.\n",
    "For instance, for store 10, predict the trends of iTEM 7 using the last 2 years as historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T19:21:51.334538Z",
     "start_time": "2020-09-20T19:21:51.332033Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tLjKa3GeRGdd"
   },
   "outputs": [],
   "source": [
    "# Analyse your data\n",
    "#    Make appropriate visualisations or data manipulations\n",
    "#    The goal is to understand the kind of data you are dealing with\n",
    "#    Check if there are seasonal trends\n",
    "#    And other things that you might find relevant to augment your business concern\n",
    "\n",
    "\n",
    "# Forecasting:\n",
    "# Separate our dataset into two samples:\n",
    "#    A training set, which will be used to fit our data\n",
    "#    A test set, which will be used to test how good our model is predicting the data\n",
    "# 1. SEPARATE OUR DATASET:\n",
    "\n",
    "# we will split our data by selecting the last 2 months for prediction and the \n",
    "# remaining data for training\n",
    "\n",
    "\n",
    "# Allocate the data for training\n",
    "\n",
    "# Put the remaining data of our dataset \n",
    "\n",
    "\n",
    "# Select a predictive algorithm (a model to learn from our data)\n",
    "\n",
    "\n",
    "\n",
    "# Fit our sample of data to this model\n",
    "\n",
    "\n",
    "# Make prediction\n",
    "\n",
    "# Apply the seasonal decomposition method to our sales dataset for a monthly frequency\n",
    "# to determine the trend\n",
    "\n",
    "\n",
    "# Evaluate how good the model is\n",
    "\n",
    "\n",
    "# After being happy with your parameters and your results, train the model with \n",
    "# the entire dataset and predict the next 60 days as asked in the task\n",
    "# what are your findings? What do you recommend to the CEO?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcG2RKqQYQOn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "08-lab-nb.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
