{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tutorial :: Internal data (Strengths and weaknesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recommended reading:\n",
    "\n",
    "[A review and future direction of agile, business intelligence, analytics and data science](https://doi-org.ezp01.library.qut.edu.au/10.1016/j.ijinfomgt.2016.04.013)\n",
    "\n",
    " Criteria | Analytics Type | Analytics Objective | Data Type | Data Age\n",
    "---|---|---|---|---\n",
    "Traditional Business Intelligence | Descriptive, Predictive |Decision Support, Performance Management | Structured and Defined | >24 h\n",
    "Fast Analytics with Big Data | Predictive, Prescriptive | Drive the Business | Unstructured, Undefined | <Min\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kinds of Analytics\n",
    "\n",
    "* **Descriptive analytics**\n",
    "    - Interpretation of historical data to better understand changes that have happened in a business. \n",
    "    - Describes the past using a range of data to draw comparisons\n",
    "    - Usually consists in reports such as year-over-year pricing changes, month-over-month sales growth, the number of users, or the total revenues\n",
    "    - Performance metrics can be used to flag areas of **strength** and **weakness** in order to inform management’s strategy.\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Predictive analytics**\n",
    "    - Used to make **predictions** about unknown future events.\n",
    "    - Describes the use of statistics and modeling to determine **future performance** based on current and historical data.\n",
    "    - Looks at **patterns** in data to determine if those patterns are likely to emerge again, which allows businesses and investors to **adjust** where they use their **resources** in order to take **advantage** of possible future events.\n",
    "    - Example:  marketers look at how consumers have reacted to the overall economy when planning on a new campaign, and can use shifts in demographics to determine if the current mix of products will attract consumers to make a purchase.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Prescriptive analytics**\n",
    "  - Uses technology to help businesses make better decisions about how to handle specific situations by factoring in knowledge of possible situations, available resources, past performance and what is currently happening. \n",
    "  - Uses statistics and modeling to determine future performance based on current and historical data — to improve business decisions despite uncertainty and changing conditions, and to help companies determine what action to take.\n",
    "  - Can help prevent fraud, limit risk, increase efficiency, meet business goals and create more loyal customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/Three_Phases_of_Analytics.png\" />\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predictive Anaytics: Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Forecasting is the process of making predictions of the future based on past and present data and most commonly by analysis of trends\n",
    "\n",
    "<img src=\"https://i2.cdn.turner.com/money/2012/01/02/markets/stock_market_outlook_survey/chart-sp500-stock-outlook.top.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The more recorded past data there is, the more accurate the forecast model is. Although, it is always hard to forecast unexpected events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* New companies, using guesswork when they use sales forecasting strategies, because they do not hold enough data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strengths**\n",
    "*  Forces a company to think about how it intends to monitor and track sales beyond the current period\n",
    "* Adjust the business strategy based on its prediction for sales growth\n",
    "* If a seasonal pattern in sales is noticed, one can hire or reduce staff accordingly\n",
    "* Track sales per item and use this information to focus stronger selling products and services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weaknesses**\n",
    "* Limited data mitigates the effectiveness of putting together a sales forecast.\n",
    "* Past sales results are not always indicative of future sales results (very important)!\n",
    "* Sales forecasting uses some form of projection about future demand interpreted through consumer preferences, opinions and attitudes.\n",
    "* Consumer demand is a moving target, which makes hard future projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Things to take into consideration in Forecasting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seasons (Winter, Summer, Autumn, Spring, Easter, Holidays, Christmas, etc)\n",
    "* Unpredictable Revenue\n",
    "* Revenue based on sales forecasts is only moderately predictable.\n",
    "* The longer that we try to forecast, the higher the errors (always go for short term forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "# Forecasting libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "file = 'data/week-10/sales_ex.csv'\n",
    "data = pd.read_csv( file )\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the time period of this dataset\n",
    "max_period = data['date'].???\n",
    "min_period = data['date'].???\n",
    "\n",
    "print( 'This dataset has been collecte from ' + str(min_period) + ' to ' + str(max_period)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index data by date\n",
    "data['date'] = pd.to_datetime(data.date,format=???)\n",
    "data.set_index('date', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sales throughout time\n",
    "data['sales'].plot( figsize=(10, 5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sales plot seems to indicate a pattern: it reaches its peak in the middle of the year (summer) and its minimum in the end of the year (December). Can you imagine an item that displays such behaviour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we see that our sales graph seems to be like a signal composed of three elements: the actual sales behaviour, the seasonal trends and some noise (data that does not fit in the patterns of the sales neither in seasonal trends).\n",
    "\n",
    "We can decompose this signal by using Python's *seasonal_decompose* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the general trends and sesonality of the sales\n",
    "decomposed_sales = sm.tsa.seasonal_decompose(data, period=365)\n",
    "ax = decomposed_sales.plot( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By anaysing past data, we can make some descriptive anaytics about the sales. We see that there is a general trend for the sales to increase, but there are lots of fluctuations due to seasons and also some considerable amount of noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Data into Training set and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to forecast our data using our daily sales dataset. The first thing that it is important to know is the size of this datastet. Since this is a forecast approach, we will use the majority of our data to train our model and we will reserve the last 3 months to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SEPARATE OUR DATASET:\n",
    "total_sales = len(data)\n",
    "\n",
    "# we will split our data by selecting the last 3 months for prediction and the \n",
    "# remaining data for training\n",
    "data_split = 90 # 90 days corresponds to the three months\n",
    "\n",
    "# Allocate the data for training\n",
    "train = data.iloc[0: ???]\n",
    "\n",
    "# Put the remaining data of our dataset for testing\n",
    "expected = data.iloc[???: ]\n",
    "\n",
    "print('Total datapoints in the dataset: ' + str( total_sales )) \n",
    "print('Datapoints reserved for training: ' + str(len(train)))\n",
    "print('Datapoints reserved for testing: ' + str(len(expected)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the type of learning algorithm that we want to apply. Python's statistical libraries offer us a wide range of learning algorithms that you can explore. We will explore the Seasonal ARIMA algorithm, also known as SARIMAX, which is based on a particular statistical learning method called Linear Regression.\n",
    "\n",
    "<img src=\"https://josef-pkt.github.io/pages/slides/images/airpassenger_forecast.png\" />\n",
    "\n",
    "There are four distinct integers (p, d, q, s) that are used to parametrize the SARIMAX model\n",
    "\n",
    "* p (AR parameters) is the auto-regressive part of the model. It allows us to incorporate the effect of past values into our model. Intuitively, this would be similar to stating that it is likely to be warm tomorrow if it has been warm the past 3 days.\n",
    "\n",
    "* d (differences) is the integrated part of the model. This includes terms in the model that incorporate the amount of differencing (i.e. the number of past time points to subtract from the current value) to apply to the time series. Intuitively, this would be similar to stating that it is likely to be same temperature tomorrow if the difference in temperature in the last three days has been very small.\n",
    "\n",
    "* q (MA parameters) is the moving average part of the model. This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past.\n",
    "\n",
    "* s is the periodicity of the time series (4 for quarterly periods, 12 for yearly periods, etc.).\n",
    "\n",
    "Here, (p, d, q) are the non-seasonal parameters described above, while (P, D, Q) follow the same definition but are applied to the seasonal component of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. DEFINE THE LEARNING ALGORITHM\n",
    "# In this case we will use Python's forecast algorithm, SARIMAX\n",
    "# If you are curious, you can find more information here (including information about params):\n",
    "# http://people.duke.edu/~rnau/411home.htm\n",
    "# We fit the model by instantiating a new SARIMAX class with the following arguments:\n",
    "# trainig set\n",
    "# order: contains a set of 3 parameters that will help to fit the dats (p, d, q). These parameters\n",
    "#        need to be manually chosen and are usually found by conducting several trials\n",
    "# seasonal_order: contains a set of 4 parameters that will help to fit the dats (P, D, Q, s). These parameters\n",
    "#                 need to be manually chosen and are usually found by conducting several trials\n",
    "# enforce_stationarity: Whether or not to transform the AR parameters to enforce stationarity in the autoregressive component of the model\n",
    "# enforce_invertibility: Whether or not to transform the MA parameters to enforce invertibility in the moving average component of the model \n",
    "model_sarimax = SARIMAX(train, order=(4,2,4), \n",
    "                                        seasonal_order=(5,1,5,5),\n",
    "                                        enforce_stationarity=False,\n",
    "                                        enforce_invertibility=True)\n",
    "model_sarimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit data to model\n",
    "After defining our learning model and pluging in the right learning parameters, we need to fit our data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT THE DATA\n",
    "model_fit = model_sarimax.fit()\n",
    "\n",
    "# You can see the general results of this model including:\n",
    "# coef: the coeffiecients that were learned to for the data\n",
    "# std err: the error obtained while fitting the data\n",
    "# some extra information about statistical evaluation and confidence intervals\n",
    "print( model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Results (Forecast Data)\n",
    "Let's use SARIMAX to try to estimate the last 3 months of our dataset. This way we can see how well SARIMAX performed, since we have the true sales of the store for that time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MAKE PREDICTIONS\n",
    "start = len(train)\n",
    "end = total_sales\n",
    "\n",
    "expected['forecast_SARIMAX'] = model_fit.predict(start = start, end = end, dynamic= True)  \n",
    "fig = expected[['sales','forecast_SARIMAX']].plot(figsize=(12, 8))\n",
    "\n",
    "# Apply the seasonal decomposition method to our sales dataset for a monthly frequency\n",
    "# to determine the trend\n",
    "decomposed_sales_sarimax = sm.tsa.seasonal_decompose(expected['sales'], model='adjust', period=30)\n",
    "decomposed_sales_sarimax.trend.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Forecast\n",
    "In order to have a numerical validation of the model, instead of jus a graphical one, we can use an error metric called *Mean Squared Error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the error:\n",
    "error_sarimax = mean_squared_error( expected['sales'], expected['forecast_SARIMAX'])\n",
    "print('SARIMAX model Mean Squares Error: ' + str(error_sarimax))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it yourself\n",
    "\n",
    "Try changing the parameters that we used to train the model. Can you obtain a forecast with an error smaller than 337?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting\n",
    "Assuming that this was the best model that we could obtain with a certain set of parameters, then we can use the entire dataset now to train it and see the futture sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Learning Model\n",
    "model = SARIMAX(data['sales'], order=(4,2,4), \n",
    "                                        seasonal_order=(5,1,5,5),\n",
    "                                        enforce_stationarity=False,\n",
    "                                        enforce_invertibility=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Data\n",
    "model_fit = model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for 3 months\n",
    "start = len(data)\n",
    "end = total_sales + 90\n",
    "\n",
    "predictions = model_fit.predict(start = start, end = end, dynamic= True)\n",
    "\n",
    "full_data = data['sales'].append(predictions)\n",
    "full_data.plot( figsize=(12, 8) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the last year for better visualisation\n",
    "last_year_train = full_data.iloc[0: len(full_data) - 305]\n",
    "last_year_pred = full_data.iloc[len(full_data) - 305:]\n",
    "last_year_train.plot( figsize=(12, 8) )\n",
    "last_year_pred.plot( figsize=(12, 8) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Top 10 Analytics and BI Software Vendors and Market Forecast 2016-2021](https://www.appsruntheworld.com/top-10-analytics-and-bi-software-vendors-and-market-forecast/)\n",
    "\n",
    "\n",
    "* [SAP](https://www.sap.com/products/analytics/business-intelligence-bi.html)\n",
    "* [SAS](https://www.sas.com/en_au/solutions/business-intelligence.html)\n",
    "* [IBM](https://www.ibm.com/au-en/marketplace/business-intelligence)\n",
    "* [Oracle](https://www.oracle.com/solutions/business-analytics/business-intelligence/index.html)\n",
    "* [Tableau](https://www.tableau.com)\n",
    "* [Microsoft](https://powerbi.microsoft.com/en-us/)\n",
    "* [Qlik](https://www.qlik.com/us/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Big Data Connection\n",
    "\n",
    "* Hadoop - HDFS and MapReduce - [Big Data, Hadoop, and Spark: An Explanation for the Rest of Us (part 1)](https://community.alteryx.com/t5/Engine-Works-Blog/Big-Data-Hadoop-and-Spark-An-Explanation-for-the-Rest-of-Us-Part/ba-p/2796)\n",
    "* Apache Spark - [Big Data, Hadoop, and Spark: An Explanation for the Rest of Us (part 2)](https://community.alteryx.com/t5/Engine-Works-Blog/Big-Data-Hadoop-and-Spark-An-Explanation-for-the-Rest-of-Us-Part/ba-p/16560)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
