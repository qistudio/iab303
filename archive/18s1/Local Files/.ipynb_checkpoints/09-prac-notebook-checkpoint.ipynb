{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">IAB303 - Business Intelligence - <a href=\"0%20-%20IAB303%20Overview.ipynb\">overview</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRACTICAL :: Trust and other human factors in business data analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***It is possible for analysis to be acurate without being fair.***\n",
    "\n",
    "Consider a scenario where we are analysing data from a survey completed by employees from a company. The employees were asked to rank how fair they believe their workplace to be on a scale as follows:\n",
    "\n",
    "1. Very unfair\n",
    "2. Unfair\n",
    "3. Mostly fair\n",
    "4. Fair\n",
    "5. Very fair\n",
    "\n",
    "Our analysis will give feedback to the company management on how well the company is doing in being fair to it's workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "file = 'fair-workplace-survey.csv'\n",
    "df = pandas.read_csv(file, index_col=???) #Add the index column name\n",
    "ratings = df[???] #Add the column name that holds the ratings\n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 responses to the survey. Let's see what the average rating is to give us an idea of the overall fairness..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What function will produce the average?\n",
    "ratings.???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is looking good. The average rating is between 'Mostly fair' and 'Fair'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The average problem\n",
    "\n",
    "Consider what the average would be if we had 10 'Very unfair' (1) responses, and 10 'Very fair' (5) responses.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{(10\\times 1) + (10\\times 5)}{20} = 3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is 'Mostly fair' even though half of the people said 'Very unfair' and the other half 'Very fair'. Do you think that this is a *fair* interpretation?\n",
    "\n",
    "However, this type of bipolar distribution is unusual. Let's check the shape of our actua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ratings.hist(bins=???) #How many bins do we need to get an acurate picture?\n",
    "plt.set(title='Number of ratings',xlabel='rating', ylabel='count')\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better. It looks like the highest rating was 4 which is very good news for the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digging deeper\n",
    "\n",
    "However, if we consider the human factors behind the data, would the results be so positive?\n",
    "\n",
    "Although the survey was anonymous, we have 2 other types of information available: the gender and role of the respondants. Our respondants indicated whether they are Male or Female and if they are a Worker or a Supervisor.\n",
    "\n",
    "What's the average rating for a female worker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaleWorker = df.loc[(df[???] == ???) & (df[???] == ???)] # Column names and values for female, and worker\n",
    "femaleWorker['FairWorkPlace'].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare with the average that we calculated above?\n",
    "\n",
    "Let's get a better idea by segmenting the data and finding the averages of each segment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of True/False to obtain the key segments\n",
    "female = (df[???] == ???)\n",
    "male = (df[???] == ???)\n",
    "worker = (df[???] == ???)\n",
    "supervisor = (df[???] == ???)\n",
    "\n",
    "# A function to pass the lists and obtain the average rating\n",
    "def averageRating(type1,type2):\n",
    "    return df.loc[type1 & type2]['FairWorkPlace'].mean(0)\n",
    "\n",
    "# Create a dictionary with our segments\n",
    "segments = {}\n",
    "segments['FemaleWorker'] = averageRating(???,???)\n",
    "segments['FemaleSupervisor'] = averageRating(???,???)\n",
    "segments['MaleWorker'] = averageRating(???,???)\n",
    "segments['MaleSupervisor'] = averageRating(???,???)\n",
    "segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells a different story than our first histogram. Let's visualise this data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = list(segments.keys())\n",
    "values = list(segments.values())\n",
    "\n",
    "plt.bar(range(len(segments)),values,tick_label=names)\n",
    "plt.xticks(rotation=20)\n",
    "plt.suptitle('Workplace Fairness Ratings (by Segment)', fontsize=14)\n",
    "plt.xlabel('Gender-Role', fontsize=13)\n",
    "plt.ylabel('Average Rating', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we learn?\n",
    "\n",
    "* What is the story of the segment visualisation?\n",
    "* How does this different from the original story?\n",
    "* Was the first analysis wrong?\n",
    "* If we didn't dig deeper, how fair would our analysis be?\n",
    "* What is the difference between accurate analysis and fair analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more complex example\n",
    "\n",
    "Read through the following example which explains how similar biases can occur when working with more complicated machine learning algorithms:\n",
    "\n",
    "[Google Developers - Text Embedding Models Contain Bias. Here's Why That Matters.](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html?m=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
