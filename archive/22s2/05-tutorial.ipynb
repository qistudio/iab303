{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Tutorial - Social Media Analysis\n",
    "\n",
    "In this tutorial, we'll be looking at one possible way of extracting data from a social media outlet, namely, Twitter. In doing so, we'll also conduct some basic sentiment analysis, and implement an appropriate form of visualisation for our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Data From A 'Social Media' API - Twitter Data\n",
    "\n",
    "### [1] Question - Finding 'Trending' Topics For Publication\n",
    "\n",
    "Let us consider the business concern of today's tutorial:\n",
    "\n",
    "> **CONCERN:** A popular news publication in Brisbane has been trying to improve their readership. Ways of doing this could possibly include covering more relevant topics, or understanding how readers feel about said topics. They have reached out to you for assistance regarding this matter, in hopes that it could meaningfully guide their understanding over what articles to publish. Can you assist them?\n",
    "\n",
    "As given by the business concern, the question focuses on improving readership of a news publication.\n",
    "\n",
    ">**QUESTION:** What possible forms of information are relevant for this question?\n",
    "\n",
    ">>**ANSWER:** ???\n",
    "\n",
    "Partial to this question, a second question emerges:\n",
    "\n",
    ">**QUESTION:** Where might we acquire this information?\n",
    "\n",
    ">>**ANSWER:** ???\n",
    "\n",
    "__NOTE:__ Be careful in your answer. Despite the quality of information that certain sources give, the degree of 'set up' required to retrieve such information can be beaten by alternative sources that are only slightly less helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Data - Finding 'Trending' Topics For Publication\n",
    "\n",
    "\n",
    "For this task, we are going to be delving into the 'Twittosphere' (Twitter) as our choice of social media for the business concern. As such, there are some necessary steps to set up our interface for the analytics process.\n",
    "\n",
    "__NOTE:__ These instructions assume that you have a Twitter account, and that you are currently signed into your account in your web browser.\n",
    "\n",
    "To gather data from Twitter, we will need to create a Twitter App. This is essentially a small intermediate application that allows you to connect with Twitter. You can read more about it here: https://developer.twitter.com/en/products/twitter-api\n",
    "\n",
    ">**QUESTION:** Why does Twitter require that individuals use apps to connect to their service?\n",
    "\n",
    ">>**ANSWER:** ???\n",
    "\n",
    "__Step 1.__ Go to the website URL entitled https://developer.twitter.com/en/apps/, and click the _Create An App_ button in the top right corner:\n",
    "\n",
    "<img src=\"graphics/5_s_1.png\" style=\"margin-left: 50px; width: 40%;\">\n",
    "\n",
    "__Step 2.__ In the form that appears, you will need to fill in the fields entitled _App Name_, _Web URL_, _App Description_, and the question regarding how the app will be used. Give the app a unique and meaningful name, state https://qut.edu.au for the web URL, and feel free to provide a paraphrase of the following statement for both the description of the app, as well as how it will be used:\n",
    "\n",
    ">_This is an app that we will be using for academic purposes, to understand what people are feeling with relation to certain topics on Twitter._\n",
    "\n",
    "\n",
    "<img src=\"graphics/5_s_2.png\" style=\"margin-left: 50px; width: 40%;\">\n",
    "\n",
    "__Step 3.__ Once you have completed the form, click _Submit_, and then select the _Create_ button in the _Developer Terms_ window that appears:\n",
    "\n",
    "<img src=\"graphics/5_s_3.png\" style=\"margin-left: 50px; width: 40%;\">\n",
    "\n",
    "__Step 4.__ You should then be directed to a page that contains information about the new Twitter _App_ that you have created. Click the _Keys and Tokens_ tab, and then scroll down:\n",
    "\n",
    "<img src=\"graphics/5_s_4.png\" style=\"margin-left: 50px; width: 40%;\">\n",
    "\n",
    "__Step 5.__ Note your _API Key_ and _API Secret_. You will need these for the upcoming analysis:\n",
    "\n",
    "<img src=\"graphics/5_s_5.png\" style=\"margin-left: 50px; width: 40%;\">\n",
    "\n",
    "__Step 6.__ Lastly, click the _Generate_ button overheading the _API Token_ section. In the window that appears, note both the _Access Token_ and _Access Secret_ that have been created:\n",
    "\n",
    "<img src=\"graphics/5_s_6.png\" style=\"margin-left: 50px; width: 40%;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] Analysis - Twitter Trend Discovery, Tweet Retrieval And Sentiment Analysis\n",
    "\n",
    "Now we can begin our analysis. We're going to start by installing the __tweepy__ package, which is used to access your Twitter App in the Python interface. We'll install the package by running the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will import the required packages:\n",
    "\n",
    "#### You will need to use the following python commands:\n",
    "\n",
    "```python\n",
    "    import\n",
    "```\n",
    "\n",
    "#### And you will need to import the following packages:\n",
    "\n",
    "```python\n",
    "    tweepy\n",
    "    numpy\n",
    "    pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import ???           # To access and consume Twitter's API\n",
    "import ??? as pd     # To handle data\n",
    "import ??? as np      # For number computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll validate that we can successfully connect to Twitter. Noting the steps of the __Data__ phase of our analytics process, fill in the required fields to set up the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter App access keys\n",
    "\n",
    "APP_KEY    = ???\n",
    "APP_SECRET = ???\n",
    "\n",
    "ACCESS_TOKEN  = ???\n",
    "ACCESS_SECRET = ???\n",
    "\n",
    "# API's setup:\n",
    "def connectToTwitterAPI():\n",
    "    \"\"\"\n",
    "    Utility function to setup the Twitter's API\n",
    "    with access keys.\n",
    "    \"\"\"\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(APP_KEY, ???)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ???)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling the business concern, we're interested in finding out what trends are most relevant in Brisbane. To do this, we'll need to review the __tweepy__ documentation (see this URL: http://docs.tweepy.org/en/v3.5.0/api.html#).\n",
    "\n",
    ">**QUESTION:** Are there any functions that can help us find out what is trending in Brisbane?\n",
    "\n",
    ">>**ANSWER:** ???\n",
    "\n",
    "Next, we are going to use the functions we've found to find out what is trending in Brisbane. Let's go ahead and firstly get the details of Brisbane (according to Twitter):\n",
    "\n",
    "#### You will need to use the following python commands:\n",
    "\n",
    "```python\n",
    "    connectToTwitterAPI()\n",
    "    api.trends_closest() # HINT: The latitude and longitude of Brisbane are -27.476102 and 153.028024\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the API:\n",
    "api = ???()\n",
    "\n",
    "api.???(???, ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**QUESTION:** From looking at the data that was returned, what can be said about how Twitter interprets Brisbane?\n",
    "\n",
    ">>**ANSWER:** ???\n",
    "\n",
    "Next, let's extract the trends from Brisbane:\n",
    "\n",
    "#### You will need to use the following python commands:\n",
    "\n",
    "```python\n",
    "    api.trends_place()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_trends = api.???(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a basic look at the data, through a sample (what can be said about it?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???[0][???][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a dataframe that groups the popular trending tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_volume = []\n",
    "trend_hashtag = []\n",
    "\n",
    "# Populate the data structure from the extracted trends\n",
    "for trend in ???:\n",
    "    if trend[???] != None:\n",
    "        trend_hashtag.append(trend[???])\n",
    "        trend_volume.append(trend[???])\n",
    "\n",
    "# Make a new dataframe\n",
    "trend_hashtag_volume = pd.DataFrame({'Hashtag':???, 'Volume':???}) \n",
    "trend_hashtag_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this data is excellent for helping us understand what is trending through Twitter, it's only part of the concern. Recall that the client wants us to also find out how individuals feel about said topics.\n",
    "\n",
    "To explore this topic, we can firstly grab some tweets from one of the popular hashtags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = api.search(q=???, count=50)\n",
    "\n",
    "# Print the total number of extracted tweets\n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(???)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can display the 5 most recent tweets from this hashtag, and observe the nature of extracted tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the most recent 5 tweets:\n",
    "print(\"5 recent tweets:\\n\")\n",
    "for tweet in tweets[:???]:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we can organise these tweets in a more appropriate fashion. Let's construct a dataframe for our data, and then display the first 10 tweets from said dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe as follows:\n",
    "data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "# Add relavant data from each tweet:\n",
    "data['len']  = np.array([len(tweet.text) for tweet in tweets]) #textual content legnth\n",
    "data['ID']   = np.array([tweet.id for tweet in tweets])\n",
    "data['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "data['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "data['Likes']  = np.array([tweet.favorite_count for tweet in tweets]) #likes counts\n",
    "data['RTs']    = np.array([tweet.retweet_count for tweet in tweets]) #retweets count\n",
    "\n",
    "# Display the first 10 elements of the dataframe:\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might we go about finding the most liked, or retweeted tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Extract the tweet with more FAVs and more RTs:\n",
    "\n",
    "maxLikes = np.???(data['Likes'])\n",
    "maxRetweets  = np.???(data['RTs'])\n",
    "\n",
    "fav = data[data.Likes == ???].index[0]\n",
    "rt  = data[data.RTs == ???].index[0]\n",
    "\n",
    "# Max FAVs:\n",
    "print(\"The tweet with more likes is: \\n{}\".format(data['Tweets'][fav]))\n",
    "print(\"Number of likes: {}\".format(maxLikes))\n",
    "\n",
    "# Max RTs:\n",
    "print(\"The tweet with more retweets is: \\n{}\".format(data['Tweets'][rt]))\n",
    "print(\"Number of retweets: {}\".format(maxRetweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the techniques we've explored are great for retrieving tweets, and understanding their statistics. However, our client wants to go a bit further to actually understand how individuals are feeling. For such a task, we are fortunate that a Python package can help us achieve this goal.\n",
    "\n",
    "The API known as __textblob__ is capable of understanding whether someone is conveying themself in a positive or negative fashion through their tweet. It has an already trained analyzer to classify the polarity of a given text. We define two functions in the following code. One to pre-process and clean the tweet content and the other to compute the sentiment associated with each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ??? import TextBlob\n",
    "import re\n",
    "\n",
    "def cleanTweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analyseSentiment(???):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    '''\n",
    "    analysis = TextBlob(???(???))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can compute the sentiment for each tweet and add it to the dataframe we created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentiment for each tweet and add the result into a new column:\n",
    "data['SA'] = np.array([ analyseSentiment(tweet) for tweet in data['Tweets'] ])\n",
    "\n",
    "# Display the first 10 elements of the dataframe:\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**QUESTION:** From looking at the sentiment analysis results conducted on the following tweets, what can be said about how the authors of these tweets were feeling?\n",
    "\n",
    ">>**ANSWER:** ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] Visualisation - Pie Charts\n",
    "\n",
    "As perhaps evident in the previous step, reading sentiment off of a dataframe is quite difficult. That is why we will now implement a graphing technique - specifically a pie chart - to visualise the sentiment of our tweeters.\n",
    "\n",
    "Let's begin by calculating the percentages of positive, negative, and neutral tweets for our previously examined hashtag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lists with classified tweets:\n",
    "\n",
    "positiveTweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] ? ???]\n",
    "neutralTweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] ?? ???]\n",
    "negativeTweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] ? ???]\n",
    "\n",
    "# Calculate percentages\n",
    "\n",
    "positivePercent = len(???)*100/len(data['Tweets'])\n",
    "neutralPercent = len(???)*100/len(data['Tweets'])\n",
    "negativePercent = len(???)*100/len(data['Tweets'])\n",
    "\n",
    "# Print percentages:\n",
    "\n",
    "print(\"Percentage of positive tweets: {}%\".format(???))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(???))\n",
    "print(\"Percentage de negative tweets: {}%\".format(???))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can plot the details on a pie graph. It is quite convenient that this particular visualisation technique lends itself to visualisation by percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting and visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [???, ???, ???]\n",
    "sizes = [???, ???, ???]\n",
    "\n",
    "# Set different colors\n",
    "colors = ['green', 'grey', 'red']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go even further, and also compare the popularity of our previously examined trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(trend_hashtag_volume.loc[:,'Hashtag'],trend_hashtag_volume.loc[:,'Volume'])\n",
    "plt.xticks(trend_hashtag_volume.loc[:,'Hashtag'],rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5] Insight - Answering The Concern\n",
    "\n",
    "While we've only examined one tweet in this analytics process thus far, it is now upto you to evaluate the various trending tweets, to better understand how people are feeling about various topics on Twitter. This should inform a descriptive recommendation for the business concern, and should address both of the forementioned questions regarding popularity of trends, and sentiment of readers.\n",
    "\n",
    "As some final questions, it would be worth it to consider:\n",
    "\n",
    ">**QUESTION:** Is Twitter the most accurate source for understanding sentiment of individuals? If not, why? \n",
    "\n",
    ">>**ANSWER:** ???\n",
    "\n",
    ">**QUESTION:** Was the applied sentiment analysis effective in categorising feelings of readers? \n",
    "\n",
    ">>**ANSWER:** ???\n",
    "\n",
    "\n",
    ">**QUESTION:** Is sentiment the best indicator of a topic's popularity? \n",
    "\n",
    ">>**ANSWER:** ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
